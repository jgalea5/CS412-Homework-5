{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file...\n",
      "data stored...\n",
      "converting categorical data...\n",
      "data converted...\n",
      "new file \"formatted_responses.csv\" created\n",
      "splitting data into train/dev/test files\n",
      "creating responses.tr...\n",
      "file created...\n",
      "creating responses.de...\n",
      "file created...\n",
      "creating responses.te...\n",
      "file created...\n",
      "data split completed...\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Y labels from...\n",
      "preprocessing Y labels...\n",
      "done.\n",
      "getting Y labels from...\n",
      "preprocessing Y labels...\n",
      "done.\n",
      "getting Y labels from...\n",
      "preprocessing Y labels...\n",
      "done.\n",
      "[[5. 3. 2. ... 1. 2. 2.]\n",
      " [4. 4. 2. ... 1. 1. 2.]\n",
      " [5. 5. 2. ... 1. 1. 2.]\n",
      " ...\n",
      " [5. 5. 5. ... 2. 1. 2.]\n",
      " [5. 3. 4. ... 1. 1. 2.]\n",
      " [5. 3. 3. ... 1. 2. 1.]]\n",
      "[[5. 2. 3. ... 1. 1. 1.]\n",
      " [5. 3. 4. ... 1. 1. 2.]\n",
      " [5. 4. 2. ... 2. 1. 2.]\n",
      " ...\n",
      " [4. 3. 1. ... 2. 1. 2.]\n",
      " [5. 3. 3. ... 1. 1. 2.]\n",
      " [5. 5. 4. ... 1. 2. 1.]]\n",
      "[[5. 5. 5. ... 1. 1. 2.]\n",
      " [5. 2. 1. ... 1. 1. 2.]\n",
      " [4. 3. 3. ... 1. 1. 2.]\n",
      " ...\n",
      " [5. 3. 4. ... 1. 1. 2.]\n",
      " [5. 3. 5. ... 1. 1. 2.]\n",
      " [5. 4. 4. ... 1. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "from numpy import *\n",
    "import seaborn as sns\n",
    "Xtr, Ytr = feature_label_split(\"data/responses.tr\")\n",
    "Xde, Yde = feature_label_split(\"data/responses.de\")\n",
    "Xte, Yte = feature_label_split(\"data/responses.te\")\n",
    "print(Xtr)\n",
    "print(Xde)\n",
    "print(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "from baselines import *\n",
    "import numpy as np\n",
    "\n",
    "# baseline classifier\n",
    "# most_frequent class\n",
    "base = most_frequent()\n",
    "base.train(Xtr, Ytr)\n",
    "s3 = base.predict_all(Xde)\n",
    "\n",
    "print(mean(s3==Yde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n",
      "0.8019323671497585\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from pylab import *\n",
    "\n",
    "# decision tree classifier\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=5)\n",
    "classifier.fit(Xtr, Ytr)\n",
    "s1 = classifier.predict(Xde)\n",
    "s2 = classifier.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n",
      "0.7729468599033816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from pylab import *\n",
    "\n",
    "# support vector machine\n",
    "classifier = SVC(C = 100, kernel='poly', degree=2)#,gamma=200)\n",
    "classifier.fit(Xtr, Ytr)\n",
    "svc_class1 = classifier.predict(Xde)\n",
    "svc_class2 = classifier.predict(Xte)\n",
    "print(mean(svc_class1==Yde))\n",
    "print(mean(svc_class2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# perceptron model\n",
    "classifier = Perceptron(random_state=0, max_iter= 125)\n",
    "classifier.fit(Xtr, Ytr)\n",
    "percept_model = classifier.predict(Xde)\n",
    "print(mean(percept_model==Yde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n",
      "0.821256038647343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=2, weights='uniform').fit(Xtr, Ytr)\n",
    "s1 = clf.predict(Xde)\n",
    "s2 = clf.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862745098039216\n",
      "0.8115942028985508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rand_forest = RandomForestClassifier(n_estimators=1000,max_features=50, max_depth=13, random_state=22, criterion='gini').fit(Xtr,Ytr)\n",
    "s1 = rand_forest.predict(Xde)\n",
    "s2 = rand_forest.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n",
      "0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#neural network\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(7, 2), random_state=2).fit(Xtr,Ytr)\n",
    "s1 = clf.predict(Xde)\n",
    "s2 = clf.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7254901960784313\n",
      "0.8260869565217391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(Xtr, Ytr)\n",
    "s1 = clf.predict(Xde)\n",
    "s2 = clf.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862745098039216\n",
      "0.8164251207729468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=.4, random_state=12, multi_class='ovr', max_iter=200).fit(Xtr, Ytr)\n",
    "s1 = clf.predict(Xde)\n",
    "s2 = clf.predict(Xte)\n",
    "print(mean(s1==Yde))\n",
    "print(mean(s2==Yte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
